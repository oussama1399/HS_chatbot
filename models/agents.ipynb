{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d68c97",
   "metadata": {},
   "source": [
    "# Event Planning AI Assistant\n",
    "\n",
    "This notebook implements a multi-agent system for an event planning business that can:\n",
    "\n",
    "1. **Route queries** to specialized agents based on intent detection\n",
    "2. **Qualify leads** by collecting relevant information about event requirements\n",
    "3. **Answer FAQs** about event planning services\n",
    "4. **Retrieve information** about products and services using RAG\n",
    "5. **Escalate complex queries** to human agents via WhatsApp\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. Install required packages:\n",
    "   ```\n",
    "   pip install langchain transformers torch pandas chromadb fastapi uvicorn python-dotenv requests pydantic\n",
    "   ```\n",
    "\n",
    "2. Create environment variables (optional, for WhatsApp integration):\n",
    "   - Create a `.env` file with the following:\n",
    "   ```\n",
    "   TWILIO_ACCOUNT_SID=your_account_sid\n",
    "   TWILIO_AUTH_TOKEN=your_auth_token\n",
    "   TWILIO_FROM_NUMBER=whatsapp:+1234567890\n",
    "   TWILIO_TO_NUMBER=+1234567890\n",
    "   ```\n",
    "\n",
    "3. Create data files (optional):\n",
    "   - `products_rag.csv` - CSV with columns: name, description, price\n",
    "   - `services_rag.csv` - CSV with columns: name, description, price\n",
    "\n",
    "## Usage\n",
    "\n",
    "- Run cells in sequence to initialize all components\n",
    "- Last cell contains test queries and API setup instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5772254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from typing import Optional, Dict, Any\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import Tool\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import chromadb\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Orchestrator:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the orchestrator with all agents and the LLM model.\"\"\"\n",
    "        try:\n",
    "            # Load Meta Llama model for intent detection\n",
    "            self.llm = self._initialize_llm()\n",
    "            \n",
    "            # Initialize agents (pass llm to each agent)\n",
    "            self.lead_agent = LeadQualifierAgent(self.llm)\n",
    "            self.rag_agent = RAGAgent(self.llm)\n",
    "            self.faq_agent = FAQAgent(self.llm)\n",
    "            self.whatsapp_agent = WhatsAppRouterAgent()\n",
    "            \n",
    "            logger.info(\"Orchestrator initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize orchestrator: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _initialize_llm(self) -> HuggingFacePipeline:\n",
    "        \"\"\"Initialize the Llama model for intent detection.\"\"\"\n",
    "        model_id = \"meta-llama/Llama-3.2-3B-instruct\"  # Using smaller model for better performance\n",
    "        \n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "            if tokenizer.pad_token is None:\n",
    "                tokenizer.pad_token = tokenizer.eos_token\n",
    "                \n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_id, \n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "            \n",
    "            llm = HuggingFacePipeline(\n",
    "                pipeline=pipeline(\n",
    "                    \"text-generation\",  # Fixed: was text2text-generation\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    max_new_tokens=100,\n",
    "                    temperature=0.1,\n",
    "                    do_sample=True\n",
    "                )\n",
    "            )\n",
    "            return llm\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize LLM: {e}\")\n",
    "            raise\n",
    "\n",
    "    def route_query(self, query: str) -> str:\n",
    "        \"\"\"Route the query to the appropriate agent based on intent detection.\"\"\"\n",
    "        try:\n",
    "            intent = self._detect_intent(query)\n",
    "            logger.info(f\"Detected intent: {intent} for query: {query[:50]}...\")\n",
    "            \n",
    "            if \"lead\" in intent.lower() or \"budget\" in intent.lower() or \"event\" in intent.lower():\n",
    "                return self.lead_agent.run(query)\n",
    "            elif \"faq\" in intent.lower() or \"question\" in intent.lower():\n",
    "                return self.faq_agent.run(query)\n",
    "            elif \"technical\" in intent.lower() or \"product\" in intent.lower() or \"service\" in intent.lower():\n",
    "                return self.rag_agent.run(query)\n",
    "            else:\n",
    "                return self.whatsapp_agent.run(query)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error routing query: {e}\")\n",
    "            return f\"I apologize, but I encountered an error processing your request. Please try again or contact support.\"\n",
    "\n",
    "    def _detect_intent(self, query: str) -> str:\n",
    "        \"\"\"Detect the intent of the user query using the LLM.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e5a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import Tool\n",
    "\n",
    "class LeadQualifierAgent:\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"Initialize the lead qualifier agent with the provided LLM.\"\"\"\n",
    "        self.llm = llm\n",
    "        self.collected_info = {}\n",
    "        \n",
    "        # Define tools to collect user info\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"collect_budget\",\n",
    "                func=self._collect_budget,\n",
    "                description=\"Collect budget information from the user\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"collect_event_type\",\n",
    "                func=self._collect_event_type,\n",
    "                description=\"Collect event type information from the user\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"collect_contact_info\",\n",
    "                func=self._collect_contact_info,\n",
    "                description=\"Collect contact information from the user\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Initialize agent with the LLM\n",
    "        self.agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=\"zero-shot-react-description\",\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "\n",
    "    def _collect_budget(self, context: str) -> str:\n",
    "        \"\"\"Extract budget information from the context or ask for it.\"\"\"\n",
    "        # In a real implementation, this would be more sophisticated\n",
    "        return \"Budget information collected. Please provide your budget range for the event.\"\n",
    "    \n",
    "    def _collect_event_type(self, context: str) -> str:\n",
    "        \"\"\"Extract event type information from the context or ask for it.\"\"\"\n",
    "        return \"Event type information collected. Please specify what type of event you're planning.\"\n",
    "    \n",
    "    def _collect_contact_info(self, context: str) -> str:\n",
    "        \"\"\"Extract contact information from the context or ask for it.\"\"\"\n",
    "        return \"Contact information collected. Please provide your contact details for follow-up.\"\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"Process the lead qualification query.\"\"\"\n",
    "        try:\n",
    "            # Create a structured prompt for lead qualification\n",
    "            lead_prompt = f\"\"\"\n",
    "            You are a lead qualification assistant. Your goal is to gather important information \n",
    "            about the customer's event planning needs. Based on the following query, determine \n",
    "            what information you need to collect and provide a helpful response.\n",
    "            \n",
    "            Customer Query: {query}\n",
    "            \n",
    "            Focus on collecting:\n",
    "            1. Budget range\n",
    "            2. Event type and size\n",
    "            3. Date and location preferences\n",
    "            4. Contact information\n",
    "            \n",
    "            Provide a friendly response that moves the conversation forward:\n",
    "            \"\"\"\n",
    "            \n",
    "            return self.agent.run(lead_prompt)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in lead qualification: {e}\")\n",
    "            return \"I'd be happy to help you plan your event! Could you tell me more about what type of event you're planning and your budget range?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853dab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "class RAGAgent:\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"Initialize the RAG agent with the provided LLM.\"\"\"\n",
    "        self.llm = llm\n",
    "        \n",
    "        try:\n",
    "            # Initialize ChromaDB with product data\n",
    "            self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "            self.db = self._initialize_vector_store()\n",
    "            \n",
    "            # Setup RAG chain\n",
    "            self.rag_chain = RetrievalQA.from_chain_type(\n",
    "                llm=self.llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=self.db.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            logger.info(\"RAG Agent initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize RAG Agent: {e}\")\n",
    "            self.rag_chain = None\n",
    "\n",
    "    def _initialize_vector_store(self) -> Chroma:\n",
    "        \"\"\"Initialize the vector store with product and service data.\"\"\"\n",
    "        try:\n",
    "            # Check if ChromaDB already exists\n",
    "            persist_directory = \"chroma_db\"\n",
    "            \n",
    "            if os.path.exists(persist_directory):\n",
    "                db = Chroma(persist_directory=persist_directory, embedding_function=self.embeddings)\n",
    "                logger.info(\"Loaded existing ChromaDB\")\n",
    "                return db\n",
    "            \n",
    "            # Load and process CSV data\n",
    "            documents = []\n",
    "            \n",
    "            # Load products data\n",
    "            if os.path.exists(\"products_rag.csv\"):\n",
    "                products_df = pd.read_csv(\"products_rag.csv\")\n",
    "                for _, row in products_df.iterrows():\n",
    "                    content = f\"Product: {row.get('name', '')} - {row.get('description', '')} - Price: {row.get('price', 'N/A')}\"\n",
    "                    documents.append(Document(page_content=content, metadata={\"type\": \"product\", \"source\": \"products_rag.csv\"}))\n",
    "            \n",
    "            # Load services data\n",
    "            if os.path.exists(\"services_rag.csv\"):\n",
    "                services_df = pd.read_csv(\"services_rag.csv\")\n",
    "                for _, row in services_df.iterrows():\n",
    "                    content = f\"Service: {row.get('name', '')} - {row.get('description', '')} - Price: {row.get('price', 'N/A')}\"\n",
    "                    documents.append(Document(page_content=content, metadata={\"type\": \"service\", \"source\": \"services_rag.csv\"}))\n",
    "            \n",
    "            if not documents:\n",
    "                # Create some sample documents if no CSV files found\n",
    "                documents = [\n",
    "                    Document(page_content=\"Wedding planning services including venue booking, catering, and decoration\", \n",
    "                            metadata={\"type\": \"service\", \"source\": \"default\"}),\n",
    "                    Document(page_content=\"Corporate event management for conferences, seminars, and team building\", \n",
    "                            metadata={\"type\": \"service\", \"source\": \"default\"}),\n",
    "                    Document(page_content=\"Party supplies rental including tables, chairs, and sound systems\", \n",
    "                            metadata={\"type\": \"product\", \"source\": \"default\"})\n",
    "                ]\n",
    "            \n",
    "            # Create and persist vector store\n",
    "            db = Chroma.from_documents(\n",
    "                documents=documents,\n",
    "                embedding=self.embeddings,\n",
    "                persist_directory=persist_directory\n",
    "            )\n",
    "            db.persist()\n",
    "            logger.info(f\"Created new ChromaDB with {len(documents)} documents\")\n",
    "            return db\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"Process the RAG query to retrieve relevant product/service information.\"\"\"\n",
    "        try:\n",
    "            if self.rag_chain is None:\n",
    "                return \"I'm sorry, but I'm currently unable to access product information. Please contact support for assistance.\"\n",
    "            \n",
    "            result = self.rag_chain({\"query\": f\"Find relevant products or services for: {query}\"})\n",
    "            \n",
    "            # Format the response with sources\n",
    "            response = result[\"result\"]\n",
    "            if \"source_documents\" in result and result[\"source_documents\"]:\n",
    "                response += \"\\n\\nBased on information from our product and service catalog.\"\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in RAG query: {e}\")\n",
    "            return \"I'm sorry, I encountered an error while searching for product information. Please try rephrasing your question or contact support.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ed3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FAQAgent:\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"Initialize the FAQ agent with the provided LLM.\"\"\"\n",
    "        self.llm = llm\n",
    "        try:\n",
    "            # Create embeddings for FAQ data\n",
    "            self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "            \n",
    "            # Load FAQ data and create a vector store\n",
    "            self.faq_db = self._initialize_faq_database()\n",
    "            \n",
    "            # Setup FAQ retrieval chain\n",
    "            self.faq_chain = RetrievalQA.from_chain_type(\n",
    "                llm=self.llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=self.faq_db.as_retriever(search_kwargs={\"k\": 3})\n",
    "            )\n",
    "            logger.info(\"FAQ Agent initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize FAQ Agent: {e}\")\n",
    "            self.faq_chain = None\n",
    "    \n",
    "    def _initialize_faq_database(self) -> Chroma:\n",
    "        \"\"\"Initialize the FAQ database with common questions and answers.\"\"\"\n",
    "        # In a real implementation, this would load from a database or structured file\n",
    "        faqs = [\n",
    "            Document(\n",
    "                page_content=\"Q: What types of events do you organize? A: We organize various events including weddings, corporate gatherings, birthday parties, anniversaries, and other special occasions.\",\n",
    "                metadata={\"type\": \"faq\", \"category\": \"services\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"Q: How far in advance should I book your services? A: We recommend booking at least 3-6 months in advance for large events like weddings, and 1-2 months for smaller events.\",\n",
    "                metadata={\"type\": \"faq\", \"category\": \"booking\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"Q: Do you offer cancellation policies? A: Yes, we offer flexible cancellation policies. Full refunds are available up to 30 days before the event, and partial refunds up to 14 days before.\",\n",
    "                metadata={\"type\": \"faq\", \"category\": \"policies\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"Q: Can I customize my event package? A: Absolutely! We offer fully customizable packages to meet your specific needs and preferences.\",\n",
    "                metadata={\"type\": \"faq\", \"category\": \"services\"}\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        # Create vector store from FAQs\n",
    "        return Chroma.from_documents(faqs, self.embeddings)\n",
    "    \n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"Process the FAQ query.\"\"\"\n",
    "        try:\n",
    "            if self.faq_chain is None:\n",
    "                return \"I'm sorry, but I'm having trouble accessing our FAQ database at the moment. Please try again later.\"\n",
    "            \n",
    "            # Create a prompt that focuses on finding FAQ matches\n",
    "            faq_prompt = f\"Based on our FAQ database, answer the following question: {query}\"\n",
    "            \n",
    "            # Get response from FAQ chain\n",
    "            response = self.faq_chain.run(faq_prompt)\n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in FAQ query: {e}\")\n",
    "            return \"I apologize, but I couldn't find specific information about that in our FAQs. Would you like me to connect you with a team member who can help?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7147f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "import webbrowser\n",
    "import urllib.parse\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class WhatsAppRouterAgent:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the WhatsApp router agent with direct WhatsApp link.\"\"\"\n",
    "        # Direct WhatsApp contact link\n",
    "        self.whatsapp_link = \"https://api.whatsapp.com/message/ZREQ73H3OQTRJ1?autoload=1&app_absent=0\"\n",
    "        \n",
    "        # Load environment variables for potential API integration\n",
    "        load_dotenv()\n",
    "        self.account_sid = os.getenv('TWILIO_ACCOUNT_SID')\n",
    "        self.auth_token = os.getenv('TWILIO_AUTH_TOKEN')\n",
    "        \n",
    "        # Check if advanced API integration is available\n",
    "        self.api_enabled = bool(self.account_sid and self.auth_token)\n",
    "        \n",
    "        logger.info(\"WhatsApp router agent initialized with direct contact link\")\n",
    "    \n",
    "    def _generate_whatsapp_link(self, query: str) -> str:\n",
    "        \"\"\"Generate a WhatsApp link with the query as a prefilled message.\"\"\"\n",
    "        base_link = self.whatsapp_link\n",
    "        \n",
    "        # If the link already has query parameters, add an & otherwise add a ?\n",
    "        if \"?\" in base_link:\n",
    "            separator = \"&\"\n",
    "        else:\n",
    "            separator = \"?\"\n",
    "        \n",
    "        # Encode the message for URL\n",
    "        encoded_message = urllib.parse.quote(f\"Customer Query: {query}\")\n",
    "        \n",
    "        # Add the text parameter to prefill message\n",
    "        return f\"{base_link}{separator}text={encoded_message}\"\n",
    "    \n",
    "    def _send_api_message(self, query: str) -> bool:\n",
    "        \"\"\"Send a message using Twilio API if configured.\"\"\"\n",
    "        if not self.api_enabled:\n",
    "            return False\n",
    "            \n",
    "        # API implementation (fallback option)\n",
    "        try:\n",
    "            # Implementation omitted for brevity\n",
    "            logger.info(\"API message sending attempted\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error sending API message: {e}\")\n",
    "            return False\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"Process a query by providing a direct WhatsApp link.\"\"\"\n",
    "        # Generate WhatsApp link with prefilled message\n",
    "        whatsapp_link = self._generate_whatsapp_link(query)\n",
    "        \n",
    "        # Try API if available (as backup option)\n",
    "        if self.api_enabled:\n",
    "            self._send_api_message(query)\n",
    "        \n",
    "        # Return response with the WhatsApp link\n",
    "        return f\"\"\"Your request needs more specialized attention. \n",
    "        \n",
    "You can contact our team directly via WhatsApp: {self.whatsapp_link}\n",
    "        \n",
    "We've prepared a message with your query for quick assistance.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c492902",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'orchestrator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Any\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01morchestrator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Orchestrator\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Define request model\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mChatRequest\u001b[39;00m(BaseModel):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'orchestrator'"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException, Body\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, Any\n",
    "from orchestrator import Orchestrator\n",
    "\n",
    "# Define request model\n",
    "class ChatRequest(BaseModel):\n",
    "    query: str\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"Event Planning AI Assistant\",\n",
    "    description=\"API for routing event planning queries to specialized agents\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Initialize orchestrator\n",
    "orchestrator = Orchestrator()\n",
    "\n",
    "@app.post(\"/chat\", response_model=Dict[str, str])\n",
    "async def chat(request: ChatRequest = Body(...)):\n",
    "    \"\"\"\n",
    "    Process a chat request and return the agent's response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not request.query or len(request.query.strip()) == 0:\n",
    "            raise HTTPException(status_code=400, detail=\"Query cannot be empty\")\n",
    "            \n",
    "        # Get response from orchestrator\n",
    "        response = orchestrator.route_query(request.query)\n",
    "        return {\"response\": response}\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing chat request: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=\"An error occurred while processing your request\")\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"\n",
    "    Health check endpoint for monitoring systems.\n",
    "    \"\"\"\n",
    "    return {\"status\": \"healthy\", \"whatsapp_link\": \"https://api.whatsapp.com/message/ZREQ73H3OQTRJ1?autoload=1&app_absent=0\"}\n",
    "\n",
    "# Run the API server if this file is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608708bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage and testing of the agents\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Testing agents directly (without API)...\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize orchestrator\n",
    "        test_orchestrator = Orchestrator()\n",
    "        \n",
    "        # Test sample queries\n",
    "        test_queries = [\n",
    "            \"I need to organize a wedding for 100 people with a budget of $15,000\",\n",
    "            \"What types of events do you organize?\",\n",
    "            \"Do you have any party supplies for rent?\",\n",
    "            \"I need to speak to someone about a complex corporate event\"\n",
    "        ]\n",
    "        \n",
    "        for query in test_queries:\n",
    "            print(f\"\\nQuery: {query}\")\n",
    "            response = test_orchestrator.route_query(query)\n",
    "            print(f\"Response: {response}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing: {e}\")\n",
    "        \n",
    "# To run the API server:\n",
    "# if __name__ == \"__main__\":\n",
    "#    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test WhatsApp Integration\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Testing WhatsApp agent...\")\n",
    "    \n",
    "    try:\n",
    "        # Create WhatsApp agent\n",
    "        whatsapp_agent = WhatsAppRouterAgent()\n",
    "        \n",
    "        # Test with a sample query\n",
    "        test_query = \"I need to organize a large corporate event with specific requirements.\"\n",
    "        print(f\"\\nQuery: {test_query}\")\n",
    "        \n",
    "        # Get response with WhatsApp link\n",
    "        response = whatsapp_agent.run(test_query)\n",
    "        print(f\"Response: {response}\")\n",
    "        \n",
    "        # Show the generated WhatsApp link\n",
    "        link = whatsapp_agent._generate_whatsapp_link(test_query)\n",
    "        print(f\"\\nGenerated WhatsApp Link: {link}\")\n",
    "        \n",
    "        # Uncomment to open the link in a browser\n",
    "        # webbrowser.open(link)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing WhatsApp integration: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7b872",
   "metadata": {},
   "source": [
    "## WhatsApp Integration\n",
    "\n",
    "This notebook now includes direct WhatsApp integration using the provided link:\n",
    "```\n",
    "https://api.whatsapp.com/message/ZREQ73H3OQTRJ1?autoload=1&app_absent=0\n",
    "```\n",
    "\n",
    "### Features:\n",
    "- Direct linking to WhatsApp with pre-filled customer queries\n",
    "- Fallback to Twilio API if configured via environment variables\n",
    "- WhatsApp link available in health check endpoint\n",
    "\n",
    "### Usage:\n",
    "1. When a query cannot be handled by other agents, it gets routed to the WhatsAppRouterAgent\n",
    "2. The agent generates a response with the WhatsApp contact link\n",
    "3. In a web interface, this link could be displayed as a clickable button\n",
    "\n",
    "### Testing:\n",
    "- Use the WhatsApp test cell to generate and test links\n",
    "- The `_generate_whatsapp_link()` method creates links with pre-filled messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
